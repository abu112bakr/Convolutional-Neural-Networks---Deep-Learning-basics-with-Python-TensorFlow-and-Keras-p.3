import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D
import pickle 

X = pickle.load(open("X.pickle", "rb"))
y = pickle.load(open("y.pickle", "rb"))


#consider normalizing the data. this is done by scale the data
#so min 0 max 255px
#so to scale

X = X/255.0

model = Sequential()


#LAYER 1
# (3,3) is the 3 by 3 window
#conv layer = 64unit, window=3by3 , input shape
model.add(  Conv2D(64, (3,3), input_shape = X.shape[1:])   )
#after convotuional layer we are going to pass activation layer
model.add(Activation("relu")) #actitation= rectifi linear
#now we will do pooling
model.add(MaxPooling2D(pool_size=(2,2)))

#doing this again

#LAYER2
model.add(Conv2D(64, (3,3)))  
model.add(Activation("relu")) 
model.add(MaxPooling2D(pool_size=(2,2)))

#LAYER3
# we willl flatten the layer then
# we will add a final dence layer of 64 neuron
model.add(Flatten())
model.add(Dense(64))

#LAYER4 OUTPUT LAYER
#now to make output layer
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss="binary_crossentropy", 
              optimizer="adam", 
              metrics=['accuracy'])



import numpy as np

X = np.array(X)
y = np.array(y)

# Rest of your code...

model.fit(X, y, batch_size=32, validation_split=0.1)

#model.fit(X, y, batch_size=32, validation_split=0.1) #validation 10%


